#!/usr/bin/env python3
"""
–û—Å–Ω–æ–≤–Ω–æ–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ü–µ–Ω –Ω–∞ –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è —Å —Å–∞–π—Ç–∞ fly.pl
- –ò—Å–ø—Ä–∞–≤–ª–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã —Å —Ç–∞–π–º–∞—É—Ç–∞–º–∏
- –î–æ–±–∞–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º (–Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç)
- –ë–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
"""

import asyncio
import json
import csv
import os
import sys
from datetime import datetime, timezone
from typing import List, Dict, Any, Optional
import pandas as pd
import matplotlib.pyplot as plt
from playwright.async_api import async_playwright
import logging
from price_alerts import PriceAlertManager

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('monitor.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

class TravelPriceMonitor:
    def __init__(self, config_file: str = "config.json", data_file: Optional[str] = None):
        self.config_file = config_file
        self.data_file = data_file or "travel_prices.csv"
        self.config = self.load_config()
        
    def load_config(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            logger.info(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {self.config_file}")
            return config
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
            sys.exit(1)

    async def scrape_offers_with_retry(self) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏"""
        for attempt in range(self.config['max_retries']):
            try:
                logger.info(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{self.config['max_retries']}")
                offers = await self.scrape_offers()
                if offers:
                    return offers
                else:
                    logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ –¥–∞–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≤ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}: {e}")
                if attempt < self.config['max_retries'] - 1:
                    logger.info(f"–ñ–¥–µ–º {self.config['retry_delay']} —Å–µ–∫—É–Ω–¥...")
                    await asyncio.sleep(self.config['retry_delay'])
        
        logger.error("–í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã")
        return []

    async def scrape_offers(self) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å —Å–∞–π—Ç–∞ fly.pl —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π"""
        all_offers = []
        page_number = 1
        max_price_threshold = 8100  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞ –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
        
        async with async_playwright() as p:
            browser = await p.chromium.launch(
                headless=True,
                args=[
                    '--no-sandbox',
                    '--disable-dev-shm-usage',
                    '--disable-gpu',
                    '--disable-web-security'
                ]
            )
            
            context = await browser.new_context(
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                viewport={'width': 1920, 'height': 1080}
            )
            
            page = await context.new_page()
            
            try:
                logger.info(f"–ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É: {self.config['url']}")
                
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç—ã
                page.set_default_timeout(self.config['wait_timeout'])
                
                # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É
                response = await page.goto(
                    self.config['url'], 
                    wait_until='domcontentloaded',
                    timeout=self.config['wait_timeout']
                )
                
                if not response or response.status >= 400:
                    raise Exception(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {response.status if response else 'No response'}")
                
                logger.info("–°—Ç—Ä–∞–Ω–∏—Ü–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –∂–¥–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç...")
                await page.wait_for_timeout(5000)
                
                # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ–∫–∞ –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ü–µ–Ω—ã
                while page_number <= 10:  # –ú–∞–∫—Å–∏–º—É–º 10 —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
                    logger.info(f"–ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_number}...")
                    
                    # –ò—â–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞ —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                    offers_data = await self.find_offers(page)
                    
                    if not offers_data:
                        logger.warning("–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥...")
                        offers_data = await self.find_offers_alternative(page)
                    
                        if not offers_data:
                            logger.info("–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∑–∞–≤–µ—Ä—à–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥")
                            break
                    
                    # –ü–∞—Ä—Å–∏–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                    page_offers = []
                    max_price_on_page = 0
                    
                    for i in range(len(offers_data)):
                        try:
                            element = offers_data[i]
                            offer_data = await self.extract_offer_data(element, i)
                            if offer_data and offer_data.get('price', 0) > 0:
                                page_offers.append(offer_data)
                                max_price_on_page = max(max_price_on_page, offer_data['price'])
                        except Exception as e:
                            logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è {i}: {e}")
                        continue
                    
                    if page_offers:
                        all_offers.extend(page_offers)
                        logger.info(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_number}: —Å–æ–±—Ä–∞–Ω–æ {len(page_offers)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞: {max_price_on_page:.0f} PLN")
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç–∏–≥–ª–∏ –ª–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ü–µ–Ω—ã
                        if max_price_on_page >= max_price_threshold:
                            logger.info(f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞ {max_price_threshold} PLN, –∑–∞–≤–µ—Ä—à–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥")
                            break
                    else:
                        logger.info(f"–ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_number} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
                        break
                    
                    # –ò—â–µ–º –∫–Ω–æ–ø–∫—É "–°–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞"
                    next_page_url = await self.find_next_page_url(page)
                    if not next_page_url:
                        logger.info("–ö–Ω–æ–ø–∫–∞ '–°–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∑–∞–≤–µ—Ä—à–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥")
                        break
                    
                    # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
                    logger.info(f"–ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_number + 1}...")
                    try:
                        await page.goto(next_page_url, wait_until='domcontentloaded', timeout=self.config['wait_timeout'])
                        await page.wait_for_timeout(3000)  # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                        page_number += 1
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ—Ö–æ–¥–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_number + 1}: {e}")
                        break
                
                logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ {len(all_offers)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —Å {page_number} —Å—Ç—Ä–∞–Ω–∏—Ü")
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")
            finally:
                try:
                    await browser.close()
                except:
                    pass
        
        return all_offers

    def _extract_price_limit(self) -> Optional[float]:
        """–ü—Ä–æ–±—É–µ—Ç –¥–æ—Å—Ç–∞—Ç—å –ª–∏–º–∏—Ç —Ü–µ–Ω—ã –∏–∑ URL (filter[PriceTo]=...)."""
        try:
            url = self.config.get('url', '') or ''
            import re
            m = re.search(r'(?:PriceTo]|PriceTo)=(\d+)', url)
            if m:
                return float(m.group(1))
        except Exception:
            pass
        return None

    def _load_previous_hotels_latest(self) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ü–µ–Ω—ã –ø–æ –∫–∞–∂–¥–æ–º—É –æ—Ç–µ–ª—é.

        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–æ–±–∞—Å—Ç–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –≤—Ä–µ–º–µ–Ω–∏, —á—Ç–æ–±—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –≤—ã–¥–µ–ª–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏.
        """
        try:
            filepath = os.path.join(self.config['data_dir'], self.data_file)
            if not os.path.exists(filepath):
                return pd.DataFrame()
            df = pd.read_csv(filepath)
            if df.empty or 'scraped_at' not in df.columns:
                return pd.DataFrame()
            raw = df['scraped_at'].astype(str)
            mask_tz = raw.str.contains(r"Z$|[+-]\d{2}:\d{2}$", regex=True)
            tz_series = pd.to_datetime(raw.where(mask_tz), errors='coerce', utc=True)
            tz_series = tz_series.dt.tz_convert('UTC')
            naive_series = pd.to_datetime(raw.where(~mask_tz), errors='coerce')
            try:
                naive_series = naive_series.dt.tz_localize('UTC')
            except Exception:
                pass
            ts = tz_series.combine_first(naive_series)
            df = df.assign(_ts=ts).dropna(subset=['_ts'])
            # –ë–µ—Ä–µ–º –ø–æ –∫–∞–∂–¥–æ–º—É –æ—Ç–µ–ª—é –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–ø–∏—Å—å
            idx = df.sort_values('_ts').groupby('hotel_name').tail(1).index
            latest = df.loc[idx, ['hotel_name', 'price', '_ts']].copy()
            return latest
        except Exception:
            return pd.DataFrame()

    def _append_missing_alerts(self, missing_hotels: List[str], latest_prev: pd.DataFrame):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –∞–ª–µ—Ä—Ç—ã –¥–ª—è –æ—Ç–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–æ–ø–∞–ª–∏ –∏–∑ —Ç–µ–∫—É—â–µ–π –≤—ã–±–æ—Ä–∫–∏.

        –§–æ—Ä–º–∞—Ç –∞–ª–µ—Ä—Ç–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º —Å —Ä–µ–Ω–¥–µ—Ä–µ—Ä–æ–º –¥–∞—à–±–æ—Ä–¥–∞, –Ω–æ —Å —Ç–∏–ø–æ–º 'missing'.
        """
        if not missing_hotels:
            return
        alerts_path = os.path.join(self.config['data_dir'], 'price_alerts_history.json')
        alerts_doc: Dict[str, Any] = { 'alerts': [] }
        if os.path.exists(alerts_path):
            try:
                with open(alerts_path, 'r', encoding='utf-8') as f:
                    alerts_doc = json.load(f) or { 'alerts': [] }
                    if 'alerts' not in alerts_doc or not isinstance(alerts_doc['alerts'], list):
                        alerts_doc['alerts'] = []
            except Exception:
                alerts_doc = { 'alerts': [] }

        price_limit = self._extract_price_limit()
        now_iso = datetime.now(timezone.utc).isoformat()
        for name in missing_hotels:
            try:
                prev_row = latest_prev[latest_prev['hotel_name'] == name]
                last_price = float(prev_row['price'].iloc[0]) if not prev_row.empty else None
            except Exception:
                last_price = None
            note = '–û—Ç–µ–ª—å –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –ø–æ–∏—Å–∫–∞'
            if price_limit is not None:
                note += f' (–≤–µ—Ä–æ—è—Ç–Ω–æ —Ü–µ–Ω–∞ > {int(price_limit)} PLN –ª–∏–±–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å–Ω—è—Ç–æ)'
            alerts_doc['alerts'].append({
                'type': 'missing',
                'hotel_name': name,
                'old_price': last_price,
                'new_price': None,
                'timestamp': now_iso,
                'note': note,
            })

        try:
            with open(alerts_path, 'w', encoding='utf-8') as f:
                json.dump(alerts_doc, f, ensure_ascii=False, indent=2)
        except Exception:
            logger.warning('–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∞–ª–µ—Ä—Ç—ã –æ –ø—Ä–æ–ø–∞–≤—à–∏—Ö –æ—Ç–µ–ª—è—Ö')

    def detect_missing_hotels_and_alert(self, current_offers: List[Dict[str, Any]]):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ—Ç–µ–ª–∏, –∏—Å—á–µ–∑–Ω—É–≤—à–∏–µ –∏–∑ —Ç–µ–∫—É—â–µ–π –≤—ã–¥–∞—á–∏, –∏ –ø–∏—à–µ—Ç –∞–ª–µ—Ä—Ç—ã."""
        try:
            latest_prev = self._load_previous_hotels_latest()
            if latest_prev.empty:
                return
            prev_hotels: set = set(latest_prev['hotel_name'].astype(str).tolist())
            current_hotels: set = set([ (o.get('hotel_name') or '').strip() for o in current_offers if o ])
            missing = sorted(list(prev_hotels - current_hotels))
            if missing:
                logger.info(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –æ—Ç–µ–ª–∏, –∏—Å—á–µ–∑–Ω—É–≤—à–∏–µ –∏–∑ —Ç–µ–∫—É—â–µ–π –≤—ã–¥–∞—á–∏: {len(missing)}")
                self._append_missing_alerts(missing, latest_prev)
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø—Ä–æ–ø–∞–≤—à–∏–µ –æ—Ç–µ–ª–∏: {e}")

    async def find_offers(self, page) -> List:
        """–ò—â–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ"""
        selectors_to_try = [
            '.offer-item',
            '.trip-item', 
            '.hotel-item',
            '.search-result-item',
            '[data-testid*="offer"]',
            '.result-item',
            '.offer',
            '.trip',
            '.hotel',
            '[class*="offer"]',
            '[class*="trip"]',
            '[class*="hotel"]'
        ]
        
        for selector in selectors_to_try:
            try:
                await page.wait_for_selector(selector, timeout=10000)
                elements = await page.query_selector_all(selector)
                if elements and len(elements) > 0:
                    logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(elements)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}")
                    return elements
            except:
                continue
        
        return []

    async def find_offers_alternative(self, page) -> List:
        """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π"""
        try:
            # –ò—â–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —Å —Ü–µ–Ω–∞–º–∏
            price_elements = await page.query_selector_all('[class*="price"], [class*="cost"], [class*="amount"]')
            if price_elements:
                logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(price_elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å —Ü–µ–Ω–∞–º–∏")
                return price_elements[:50]
            
            # –ò—â–µ–º –ª—é–±—ã–µ div —ç–ª–µ–º–µ–Ω—Ç—ã
            all_divs = await page.query_selector_all('div')
            if all_divs:
                logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(all_divs)} div —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
                return all_divs[:100]
                
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}")
        
        return []

    async def find_next_page_url(self, page) -> str:
        """–ò—â–µ—Ç URL —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            # –ò—â–µ–º –∫–Ω–æ–ø–∫—É "–°–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞" –∏–ª–∏ "Nastƒôpna"
            next_page_selectors = [
                'a[aria-label*="nastƒôpna"]',
                'a[aria-label*="next"]',
                'a[title*="nastƒôpna"]',
                'a[title*="next"]',
                '.pagination a:contains("Nastƒôpna")',
                '.pagination a:contains("Next")',
                '.pagination a:contains(">")',
                '.pagination a:contains("¬ª")',
                'a[class*="next"]',
                'a[class*="pagination"]',
                'button[class*="next"]',
                'button[class*="pagination"]'
            ]
            
            for selector in next_page_selectors:
                try:
                    element = await page.query_selector(selector)
                    if element:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç–ª–µ–º–µ–Ω—Ç –∞–∫—Ç–∏–≤–µ–Ω (–Ω–µ disabled)
                        is_disabled = await element.get_attribute('disabled')
                        if not is_disabled:
                            href = await element.get_attribute('href')
                            if href:
                                # –ï—Å–ª–∏ href –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π, –¥–µ–ª–∞–µ–º –µ–≥–æ –∞–±—Å–æ–ª—é—Ç–Ω—ã–º
                                if href.startswith('/'):
                                    base_url = self.config['url'].split('?')[0]
                                    return base_url + href
                                elif href.startswith('http'):
                                    return href
                                else:
                                    return self.config['url'] + '&' + href
                except:
                    continue
            
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ - –∏—â–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —Å –Ω–æ–º–µ—Ä–∞–º–∏ —Å—Ç—Ä–∞–Ω–∏—Ü
            page_numbers = await page.query_selector_all('a[href*="page"], a[href*="strona"]')
            current_page = 1
            
            for page_link in page_numbers:
                try:
                    href = await page_link.get_attribute('href')
                    text = await page_link.inner_text()
                    
                    # –ò—â–µ–º –Ω–æ–º–µ—Ä —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                    if 'active' in (await page_link.get_attribute('class') or ''):
                        try:
                            current_page = int(text.strip())
                        except:
                            pass
                    
                    # –ò—â–µ–º —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
                    try:
                        page_num = int(text.strip())
                        if page_num == current_page + 1:
                            if href:
                                if href.startswith('/'):
                                    base_url = self.config['url'].split('?')[0]
                                    return base_url + href
                                elif href.startswith('http'):
                                    return href
                                else:
                                    return self.config['url'] + '&' + href
                    except:
                        continue
                except:
                    continue
            
            # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - –∏—â–µ–º –∫–Ω–æ–ø–∫—É —Å —Ç–µ–∫—Å—Ç–æ–º "Nastƒôpna" –∏–ª–∏ "Next"
            all_links = await page.query_selector_all('a, button')
            for link in all_links:
                try:
                    text = await link.inner_text()
                    if text and ('nastƒôpna' in text.lower() or 'next' in text.lower() or text.strip() == '>' or text.strip() == '¬ª'):
                        href = await link.get_attribute('href')
                        if href:
                            if href.startswith('/'):
                                base_url = self.config['url'].split('?')[0]
                                return base_url + href
                            elif href.startswith('http'):
                                return href
                            else:
                                return self.config['url'] + '&' + href
                except:
                    continue
            
            return ""
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}")
            return ""

    async def extract_offer_data(self, element, index: int) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —ç–ª–µ–º–µ–Ω—Ç–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç —ç–ª–µ–º–µ–Ω—Ç–∞
            full_text = await element.inner_text()
            if not full_text or len(full_text.strip()) < 10:
                return None
            
            # –ò—â–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –æ—Ç–µ–ª—è/—Ç—É—Ä–∞
            hotel_name = await self.extract_text_by_selectors(element, [
                'h1', 'h2', 'h3', 'h4', 'h5', 'h6',
                '.title', '.name', '.hotel-name', '.offer-title',
                '[class*="title"]', '[class*="name"]', '[class*="hotel"]'
            ])
            
            # –ò—â–µ–º —Ü–µ–Ω—É - —Å–Ω–∞—á–∞–ª–∞ –∏—â–µ–º —Ü–µ–Ω—É –∑–∞ –≤—Å–µ—Ö, –ø–æ—Ç–æ–º –∑–∞ –æ–¥–Ω–æ–≥–æ
            price = await self.extract_price_for_all(element)
            if not price:
                price = await self.extract_text_by_selectors(element, [
                    '.price', '.cost', '.amount', '.value',
                    '[class*="price"]', '[class*="cost"]', '[class*="amount"]'
                ])
            
            # –ò—â–µ–º –¥–∞—Ç—ã - –±–æ–ª–µ–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è fly.pl
            dates = await self.extract_dates_from_offer(element)
            
            # –ò—â–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å - –±–æ–ª–µ–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è fly.pl
            duration = await self.extract_duration_from_offer(element)
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            if not dates:
                dates = "20-09-2025 - 04-10-2025"  # –ò–∑ URL –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            if not duration:
                duration = "6-15 –¥–Ω–µ–π"  # –ò–∑ URL –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            
            # –†–µ–π—Ç–∏–Ω–≥ –Ω–µ –∏–∑–≤–ª–µ–∫–∞–µ–º - –Ω–µ –æ—á–µ–Ω—å –≤–∞–∂–µ–Ω
            rating = ""
            
            # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—Ç–µ–ª—è (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ –Ω–∞ –∫–∞—Ä—Ç–æ—á–∫–µ)
            image_url = await self.extract_image_url_from_offer(element)
            
            # –û—á–∏—â–∞–µ–º –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
            hotel_name = self.clean_text(hotel_name) if hotel_name else f"–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ {index + 1}"
            price_value = self.extract_price(price) if price else 0
            dates = self.clean_text(dates) if dates else ""
            duration = self.clean_text(duration) if duration else ""
            rating = self.clean_text(rating) if rating else ""
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞
            if not hotel_name or hotel_name == f"–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ {index + 1}":
                words = full_text.split()[:5]
                hotel_name = " ".join(words) if words else f"–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ {index + 1}"
            
            return {
                'hotel_name': hotel_name[:100],
                'price': price_value,
                'dates': dates[:50],
                'duration': duration[:30],
                'rating': rating[:20],
                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –º–µ—Ç–∫—É –≤ UTC —Å —Ç–∞–π–º–∑–æ–Ω–æ–π, —á—Ç–æ–±—ã —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –≤—Ä–µ–º—è –º–µ–∂–¥—É –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ –∏ CI-–∑–∞–ø—É—Å–∫–∞–º–∏
                'scraped_at': datetime.now(timezone.utc).isoformat(),
                'url': self.config['url'],
                'image_url': image_url or ""
            }
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ —ç–ª–µ–º–µ–Ω—Ç–∞ {index}: {e}")
            return None

    async def extract_image_url_from_offer(self, element) -> str:
        """–ü—ã—Ç–∞–µ—Ç—Å—è –∏–∑–≤–ª–µ—á—å URL –≥–ª–∞–≤–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –∫–∞—Ä—Ç–æ—á–∫–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
        try:
            # 1) –ü—Ä–æ–±—É–µ–º <img src> / data-src
            img_el = await element.query_selector('img')
            if img_el:
                for attr in ['src', 'data-src', 'data-original', 'data-lazy']:
                    val = await img_el.get_attribute(attr)
                    if val and val.strip() and val.startswith('http'):
                        return val.strip()
            
            # 2) –ü—Ä–æ–±—É–µ–º —Ñ–æ–Ω–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ inline-style
            bg_el = await element.query_selector('[style*="background"]')
            if bg_el:
                bg = await bg_el.get_attribute('style')
                if bg and 'url(' in bg:
                    import re
                    m = re.search(r'url\(("|")?(?P<u>[^\)"\']+)("|")?\)', bg)
                    if m:
                        url = m.group('u')
                        if url.startswith('http'):
                            return url
            
            # 3) –ü—Ä–æ–±—É–µ–º –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–π —Å—Ç–∏–ª—å (–º–µ–Ω–µ–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ)
            try:
                url = await element.evaluate("el => getComputedStyle(el).backgroundImage")
                if url and 'url(' in url:
                    import re
                    m = re.search(r'url\(("|")?(?P<u>[^\)"\']+)("|")?\)', url)
                    if m:
                        u = m.group('u')
                        if u.startswith('http'):
                            return u
            except:
                pass
        except Exception as e:
            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {e}")
        return ""

    async def extract_price_for_all(self, element) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ü–µ–Ω—É –∑–∞ –≤—Å–µ—Ö (za wszystkich)"""
        try:
            # –ò—â–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —Å —Ç–µ–∫—Å—Ç–æ–º "za wszystkich" –∏–ª–∏ "za wszystkie"
            price_elements = await element.query_selector_all('[class*="price"]')
            
            for price_element in price_elements:
                text = await price_element.inner_text()
                if text and ('za wszystkich' in text.lower() or 'za wszystkie' in text.lower()):
                    # –ò—â–µ–º —á–∏—Å–ª–æ –≤ —ç—Ç–æ–º —ç–ª–µ–º–µ–Ω—Ç–µ
                    import re
                    numbers = re.findall(r'[\d\s,]+', text.replace('.', '').replace(',', '.'))
                    if numbers:
                        return text.strip()
            
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ - –∏—â–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —Å –∫–ª–∞—Å—Å–æ–º price-view-2 (—Ü–µ–Ω–∞ –∑–∞ –≤—Å–µ—Ö)
            price_view_2 = await element.query_selector('.price-view-2, [class*="price-view-2"]')
            if price_view_2:
                text = await price_view_2.inner_text()
                if text and text.strip():
                    return text.strip()
            
            return ""
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ü–µ–Ω—ã –∑–∞ –≤—Å–µ—Ö: {e}")
            return ""

    async def extract_text_by_selectors(self, element, selectors: List[str]) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏—Å–ø–æ–ª—å–∑—É—è —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã"""
        for selector in selectors:
            try:
                sub_element = await element.query_selector(selector)
                if sub_element:
                    text = await sub_element.inner_text()
                    if text and text.strip():
                        return text.strip()
            except:
                continue
        return ""

    def clean_text(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        if not text:
            return ""
        return ' '.join(text.split())
    
    def extract_dates_from_url(self) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞—Ç—ã –∏–∑ URL –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        try:
            url = self.config.get('url', '')
            if 'whenFrom=' in url and 'whenTo=' in url:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—ã –∏–∑ URL
                import re
                when_from_match = re.search(r'whenFrom=(\d{2}-\d{2}-\d{4})', url)
                when_to_match = re.search(r'whenTo=(\d{2}-\d{2}-\d{4})', url)
                
                if when_from_match and when_to_match:
                    from_date = when_from_match.group(1)
                    to_date = when_to_match.group(1)
                    return f"{from_date} - {to_date}"
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞—Ç –∏–∑ URL: {e}")
        return ""
    
    def extract_duration_from_url(self) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑ URL –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        try:
            url = self.config.get('url', '')
            if 'duration=' in url:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑ URL
                import re
                duration_match = re.search(r'duration=(\d+):(\d+)', url)
                
                if duration_match:
                    min_days = duration_match.group(1)
                    max_days = duration_match.group(2)
                    if min_days == max_days:
                        return f"{min_days} –¥–Ω–µ–π"
                    else:
                        return f"{min_days}-{max_days} –¥–Ω–µ–π"
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ URL: {e}")
        return ""
    
    async def extract_dates_from_offer(self, element) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞—Ç—ã –≤—ã–ª–µ—Ç–∞-–ø—Ä–∏–ª–µ—Ç–∞ –∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è"""
        try:
            # –ò—â–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –¥–∞—Ç –Ω–∞ fly.pl
            date_selectors = [
                # –û—Å–Ω–æ–≤–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–∞—Ç
                '.date', '.dates', '.departure-date', '.arrival-date',
                '.travel-date', '.trip-date', '.journey-date',
                # –°–µ–ª–µ–∫—Ç–æ—Ä—ã —Å –∫–ª–∞—Å—Å–∞–º–∏
                '[class*="date"]', '[class*="departure"]', '[class*="arrival"]',
                '[class*="travel"]', '[class*="trip"]', '[class*="journey"]',
                # –°–µ–ª–µ–∫—Ç–æ—Ä—ã —Å data-–∞—Ç—Ä–∏–±—É—Ç–∞–º–∏
                '[data-date]', '[data-departure]', '[data-arrival]',
                # –°–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –ø–µ—Ä–∏–æ–¥–æ–≤
                '.period', '.range', '.from-to',
                # –°–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –≤—Ä–µ–º–µ–Ω–∏
                '.time', '.when', '.schedule'
            ]
            
            for selector in date_selectors:
                try:
                    date_elements = await element.query_selector_all(selector)
                    for date_element in date_elements:
                        text = await date_element.inner_text()
                        if text and self.is_date_text(text):
                            return self.clean_text(text)
                except:
                    continue
            
            # –ò—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ —ç–ª–µ–º–µ–Ω—Ç–∞ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–∞—Ç
            full_text = await element.inner_text()
            if full_text:
                import re
                # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ç–∏–ø–∞ "20.09 - 04.10" –∏–ª–∏ "20.09.2025 - 04.10.2025"
                date_patterns = [
                    r'\d{1,2}\.\d{1,2}\.\d{4}\s*-\s*\d{1,2}\.\d{1,2}\.\d{4}',  # 20.09.2025 - 04.10.2025
                    r'\d{1,2}\.\d{1,2}\s*-\s*\d{1,2}\.\d{1,2}',  # 20.09 - 04.10
                    r'\d{1,2}/\d{1,2}/\d{4}\s*-\s*\d{1,2}/\d{1,2}/\d{4}',  # 20/09/2025 - 04/10/2025
                    r'\d{1,2}-\d{1,2}-\d{4}\s*-\s*\d{1,2}-\d{1,2}-\d{4}',  # 20-09-2025 - 04-10-2025
                ]
                
                for pattern in date_patterns:
                    matches = re.findall(pattern, full_text)
                    if matches:
                        return matches[0]
            
            return ""
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞—Ç –∏–∑ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: {e}")
            return ""
    
    async def extract_duration_from_offer(self, element) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (–¥–Ω–∏/–Ω–æ—á–∏) –∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è"""
        try:
            # –ò—â–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ fly.pl
            duration_selectors = [
                # –û—Å–Ω–æ–≤–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                '.duration', '.nights', '.days', '.length',
                '.trip-duration', '.stay-duration', '.period',
                # –°–µ–ª–µ–∫—Ç–æ—Ä—ã —Å –∫–ª–∞—Å—Å–∞–º–∏
                '[class*="duration"]', '[class*="nights"]', '[class*="days"]',
                '[class*="length"]', '[class*="period"]',
                # –°–µ–ª–µ–∫—Ç–æ—Ä—ã —Å data-–∞—Ç—Ä–∏–±—É—Ç–∞–º–∏
                '[data-duration]', '[data-nights]', '[data-days]'
            ]
            
            for selector in duration_selectors:
                try:
                    duration_elements = await element.query_selector_all(selector)
                    for duration_element in duration_elements:
                        text = await duration_element.inner_text()
                        if text and self.is_duration_text(text):
                            return self.clean_text(text)
                except:
                    continue
            
            # –ò—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ —ç–ª–µ–º–µ–Ω—Ç–∞ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            full_text = await element.inner_text()
            if full_text:
                import re
                # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ç–∏–ø–∞ "7 dni", "7 nocleg√≥w", "7 days", "7 nights"
                duration_patterns = [
                    r'(\d+)\s*(dni|nocleg√≥w|days|nights|dni|noclegi)',  # 7 dni, 7 nocleg√≥w
                    r'(\d+)\s*(dni|nocleg√≥w|days|nights)',  # 7 dni, 7 nights
                    r'(\d+)\s*d',  # 7d
                    r'(\d+)\s*n',  # 7n
                ]
                
                for pattern in duration_patterns:
                    matches = re.findall(pattern, full_text, re.IGNORECASE)
                    if matches:
                        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å —á–∏—Å–ª–æ–º –∏ –µ–¥–∏–Ω–∏—Ü–µ–π –∏–∑–º–µ—Ä–µ–Ω–∏—è
                        return f"{matches[0][0]} {matches[0][1]}" if len(matches[0]) > 1 else f"{matches[0][0]} dni"
            
            return ""
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: {e}")
            return ""
    
    def is_date_text(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç –¥–∞—Ç—É"""
        if not text or len(text.strip()) < 5:
            return False
        
        import re
        
        # –ò—Å–∫–ª—é—á–∞–µ–º —Ä–µ–π—Ç–∏–Ω–≥–∏ TripAdvisor
        if any(keyword in text.lower() for keyword in ['tripadvisor', 'ocena', 'opinii', 'rating', 'stars']):
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–∞—Ç
        date_patterns = [
            r'\d{1,2}\.\d{1,2}\.\d{4}',  # 20.09.2025
            r'\d{1,2}\.\d{1,2}',         # 20.09
            r'\d{1,2}/\d{1,2}/\d{4}',    # 20/09/2025
            r'\d{1,2}/\d{1,2}',          # 20/09
            r'\d{1,2}-\d{1,2}-\d{4}',    # 20-09-2025
            r'\d{1,2}-\d{1,2}',          # 20-09
        ]
        
        for pattern in date_patterns:
            if re.search(pattern, text):
                return True
        
        return False
    
    def is_duration_text(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å"""
        if not text or len(text.strip()) < 2:
            return False
        
        import re
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        duration_patterns = [
            r'\d+\s*(dni|nocleg√≥w|days|nights|dni|noclegi)',
            r'\d+\s*d',
            r'\d+\s*n',
        ]
        
        for pattern in duration_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                return True
        
        return False

    def extract_price(self, price_text: str) -> float:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ü–µ–Ω—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        if not price_text:
            return 0
        
        import re
        # –ò—â–µ–º —á–∏—Å–ª–∞ –≤ —Ç–µ–∫—Å—Ç–µ
        numbers = re.findall(r'[\d\s,]+', price_text.replace('.', '').replace(',', '.'))
        if numbers:
            try:
                price_str = numbers[0].replace(' ', '')
                return float(price_str)
            except:
                pass
        return 0

    def save_data_append(self, offers: List[Dict[str, Any]]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ, –¥–æ–±–∞–≤–ª—è—è –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º"""
        if not offers:
            logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        os.makedirs(self.config['data_dir'], exist_ok=True)
        
        filepath = os.path.join(self.config['data_dir'], self.data_file)
        
        # –ù–∞—á–∏–Ω–∞—è —Å —ç—Ç–æ–≥–æ –º–æ–º–µ–Ω—Ç–∞ –ø–∏—à–µ–º –∫–∞–∂–¥—É—é –∑–∞–ø–∏—Å—å –∫–∞–∫ –Ω–æ–≤—É—é —Ç–æ—á–∫—É –∏—Å—Ç–æ—Ä–∏–∏,
        # —á—Ç–æ–±—ã –≥—Ä–∞—Ñ–∏–∫–∏ –∏ –∞–Ω–∞–ª–∏–∑ –∏–º–µ–ª–∏ –ø–æ–ª–Ω—É—é –≤—Ä–µ–º–µ–Ω–Ω—É—é —Å–µ—Ä–∏—é –¥–∞–∂–µ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π —Ü–µ–Ω.
        new_offers = offers
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        file_exists = os.path.exists(filepath)
        with open(filepath, 'a', newline='', encoding='utf-8') as csvfile:
            # –ù–µ –º–µ–Ω—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ CSV, —á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é.
            fieldnames = ['hotel_name', 'price', 'dates', 'duration', 'rating', 'scraped_at', 'url']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            if not file_exists:
                writer.writeheader()
            
            for offer in new_offers:
                # –ü–∏—à–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø–æ–ª—è (–±–µ–∑ image_url –≤ CSV)
                writer.writerow({k: offer.get(k, '') for k in fieldnames})
        
        logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–æ {len(new_offers)} –∑–∞–ø–∏—Å–µ–π (–≤–∫–ª—é—á–∞—è –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø–æ–≤—Ç–æ—Ä—ã –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏) –≤ {filepath}")

        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞—Ä—Ç—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ –æ—Ç–µ–ª—è–º –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º JSON
        try:
            images_path = os.path.join(self.config['data_dir'], 'hotel_images.json')
            images_map: Dict[str, str] = {}
            if os.path.exists(images_path):
                try:
                    with open(images_path, 'r', encoding='utf-8') as jf:
                        import json as _json
                        data = _json.load(jf)
                        if isinstance(data, dict):
                            images_map = data
                except Exception:
                    images_map = {}

            updated = 0
            for offer in new_offers:
                h = offer.get('hotel_name')
                img = (offer.get('image_url') or '').strip()
                if h and img and img.startswith('http'):
                    if h not in images_map:
                        images_map[h] = img
                        updated += 1

            if updated:
                with open(images_path, 'w', encoding='utf-8') as jf:
                    import json as _json
                    _json.dump(images_map, jf, ensure_ascii=False, indent=2)
                logger.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–∞ –∫–∞—Ä—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ—Ç–µ–ª–µ–π: +{updated}")
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å –∫–∞—Ä—Ç—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {e}")

    def create_charts(self):
        """–°–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫–∏"""
        try:
            df = self.load_data()
            
            if df.empty:
                logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤")
                return
            
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
            charts_dir = os.path.join(self.config['data_dir'], 'charts')
            os.makedirs(charts_dir, exist_ok=True)
            
            # –ì—Ä–∞—Ñ–∏–∫ 1: –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω –ø–æ –≤—Ä–µ–º–µ–Ω–∏
            plt.figure(figsize=(15, 8))
            
            # –†–æ–±–∞—Å—Ç–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –º–µ—Ç–æ–∫ –≤—Ä–µ–º–µ–Ω–∏ (—Å–º–µ—à–∞–Ω–Ω—ã–µ ISO8601 —Å/–±–µ–∑ —Ç–∞–π–º–∑–æ–Ω—ã)
            raw = df['scraped_at'].astype(str)
            mask_tz = raw.str.contains(r"Z$|[+-]\d{2}:\d{2}$", regex=True)
            tz_series = pd.to_datetime(raw.where(mask_tz), errors='coerce', utc=True)
            # –ì—Ä–∞—Ñ–∏–∫–∏ —Ä–∏—Å—É–µ–º –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ runner'–∞ (UTC)
            tz_series = tz_series.dt.tz_convert('UTC')
            naive_series = pd.to_datetime(raw.where(~mask_tz), errors='coerce')
            try:
                naive_series = naive_series.dt.tz_localize('UTC')
            except Exception:
                pass
            ts = tz_series.combine_first(naive_series)
            df = df.assign(_ts=ts).dropna(subset=['_ts'])

            daily_prices = df.groupby(df['_ts'].dt.date)['price'].agg(['mean', 'min', 'max'])
            
            plt.plot(daily_prices.index, daily_prices['mean'], marker='o', linewidth=2, label='–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞')
            plt.fill_between(daily_prices.index, daily_prices['min'], daily_prices['max'], alpha=0.3, label='–î–∏–∞–ø–∞–∑–æ–Ω —Ü–µ–Ω')
            
            plt.title('–î–∏–Ω–∞–º–∏–∫–∞ —Ü–µ–Ω –Ω–∞ –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è', fontsize=16)
            plt.xlabel('–î–∞—Ç–∞', fontsize=12)
            plt.ylabel('–¶–µ–Ω–∞ (PLN)', fontsize=12)
            plt.legend()
            plt.grid(True, alpha=0.3)
            plt.xticks(rotation=45)
            plt.tight_layout()
            
            chart_path = os.path.join(charts_dir, 'price_timeline.png')
            plt.savefig(chart_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            # –ì—Ä–∞—Ñ–∏–∫ 2: –¢–æ–ø-10 —Å–∞–º—ã—Ö –¥–µ—à–µ–≤—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
            plt.figure(figsize=(15, 8))
            top_cheap = df.nsmallest(10, 'price')
            
            bars = plt.barh(range(len(top_cheap)), top_cheap['price'])
            plt.yticks(range(len(top_cheap)), 
                      [name[:40] + '...' if len(name) > 40 else name for name in top_cheap['hotel_name']])
            
            plt.title('–¢–æ–ø-10 —Å–∞–º—ã—Ö –¥–µ—à–µ–≤—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π', fontsize=16)
            plt.xlabel('–¶–µ–Ω–∞ (PLN)', fontsize=12)
            plt.grid(True, alpha=0.3)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
            for i, (bar, price) in enumerate(zip(bars, top_cheap['price'])):
                plt.text(bar.get_width() + 50, bar.get_y() + bar.get_height()/2, 
                        f'{price:.0f} PLN', ha='left', va='center')
            
            plt.tight_layout()
            chart_path = os.path.join(charts_dir, 'top_cheap_offers.png')
            plt.savefig(chart_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            logger.info(f"–ì—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {charts_dir}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤: {e}")

    def load_data(self) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ CSV"""
        filepath = os.path.join(self.config['data_dir'], self.data_file)
        
        if not os.path.exists(filepath):
            return pd.DataFrame()
        
        try:
            df = pd.read_csv(filepath)
            return df
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return pd.DataFrame()

    def generate_report(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç"""
        try:
            df = self.load_data()
            
            if df.empty:
                logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞")
                return
            
            report_path = os.path.join(self.config['data_dir'], 'price_report.txt')
            
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("=== –û–¢–ß–ï–¢ –ü–û –ú–û–ù–ò–¢–û–†–ò–ù–ì–£ –¶–ï–ù –ù–ê –ü–£–¢–ï–®–ï–°–¢–í–ò–Ø ===\n\n")
                f.write(f"–î–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"URL: {self.config['url']}\n\n")
                
                f.write("=== –°–¢–ê–¢–ò–°–¢–ò–ö–ê ===\n")
                f.write(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {len(df)}\n")
                f.write(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ—Ç–µ–ª–µ–π: {df['hotel_name'].nunique()}\n")
                f.write(f"–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞: {df['price'].mean():.2f} PLN\n")
                f.write(f"–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞: {df['price'].min():.2f} PLN\n")
                f.write(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞: {df['price'].max():.2f} PLN\n\n")
                
                f.write("=== –¢–û–ü-5 –°–ê–ú–´–• –î–ï–®–ï–í–´–• –ü–†–ï–î–õ–û–ñ–ï–ù–ò–ô ===\n")
                top_cheap = df.nsmallest(5, 'price')
                for i, (_, row) in enumerate(top_cheap.iterrows(), 1):
                    f.write(f"{i}. {row['hotel_name']} - {row['price']:.2f} PLN\n")
                    if row['dates']:
                        f.write(f"   –î–∞—Ç—ã: {row['dates']}\n")
                    f.write(f"   –°–æ–±—Ä–∞–Ω–æ: {row['scraped_at']}\n\n")
            
            logger.info(f"–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")

    def check_price_alerts(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–µ–Ω –∏ —Å–æ–∑–¥–∞–µ—Ç –∞–ª–µ—Ä—Ç—ã"""
        try:
            alert_manager = PriceAlertManager()
            
            if alert_manager.df.empty:
                logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞–ª–µ—Ä—Ç–æ–≤")
                return
            
            # –°–∫–∞–Ω–∏—Ä—É–µ–º –≤—Å—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è >= 4%
            all_alerts = alert_manager.scan_all_price_changes(threshold_percent=4.0)
            
            # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç –æ–± –∞–ª–µ—Ä—Ç–∞—Ö
            alert_manager.save_alert_report(threshold_percent=4.0)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –≤–∞–∂–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
            price_drops = [a for a in all_alerts if a['price_change'] < 0]
            price_increases = [a for a in all_alerts if a['price_change'] > 0]
            
            if price_drops:
                logger.info(f"üö® –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(price_drops)} —Å–Ω–∏–∂–µ–Ω–∏–π —Ü–µ–Ω >= 4%!")
                for alert in price_drops[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-5 —Å–Ω–∏–∂–µ–Ω–∏–π
                    logger.info(f"üìâ {alert['hotel_name'][:50]} - {alert['price_change']:+.0f} PLN ({alert['price_change_pct']:+.1f}%)")
            
            if price_increases:
                logger.info(f"üìà –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(price_increases)} –ø–æ–≤—ã—à–µ–Ω–∏–π —Ü–µ–Ω >= 4%")
                for alert in price_increases[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-3 –ø–æ–≤—ã—à–µ–Ω–∏—è
                    logger.info(f"üìà {alert['hotel_name'][:50]} - {alert['price_change']:+.0f} PLN ({alert['price_change_pct']:+.1f}%)")
            
            logger.info("‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–ª–µ—Ä—Ç–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞–ª–µ—Ä—Ç–æ–≤: {e}")

    async def run_monitoring(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
        logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ü–µ–Ω –Ω–∞ –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è...")
        
        try:
            # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
            offers = await self.scrape_offers_with_retry()
            
            if not offers:
                logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫")
                return False
            
            # –ü–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–≤–µ—Ä—è–µ–º, –∫—Ç–æ –∏—Å—á–µ–∑ –∏–∑ –≤—ã–¥–∞—á–∏, –∏ —Å–æ–∑–¥–∞—ë–º –∞–ª–µ—Ä—Ç—ã
            self.detect_missing_hotels_and_alert(offers)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ (–¥–æ–±–∞–≤–ª—è–µ–º –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º)
            self.save_data_append(offers)
            
            # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫–∏
            self.create_charts()
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
            self.generate_report()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–µ–Ω –∏ —Å–æ–∑–¥–∞–µ–º –∞–ª–µ—Ä—Ç—ã
            self.check_price_alerts()
            
            logger.info("‚úÖ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            return False

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏: --config, --data-file
    import argparse
    parser = argparse.ArgumentParser(description="Travel price monitor")
    parser.add_argument("--config", default="config.json", help="–ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É JSON")
    parser.add_argument("--data-file", default=None, help="–ò–º—è CSV —Ñ–∞–π–ª–∞ –¥–∞–Ω–Ω—ã—Ö (–≤–Ω—É—Ç—Ä–∏ data_dir)")
    args = parser.parse_args()

    monitor = TravelPriceMonitor(config_file=args.config, data_file=args.data_file)
    
    try:
        success = asyncio.run(monitor.run_monitoring())
        if success:
            print("‚úÖ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
            sys.exit(0)
        else:
            print("‚ùå –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω —Å –æ—à–∏–±–∫–∞–º–∏")
            sys.exit(1)
    except KeyboardInterrupt:
        logger.info("–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(1)
    except Exception as e:
        logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()

